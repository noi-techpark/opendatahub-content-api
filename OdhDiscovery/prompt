we are about to create a discovery web application to let users, developers and maintainers to browse the data contained in my data sharing platform. before diving into that we need to create some meaningful context.
we have 2 different services: content and timeseries. content handles and serves static / medatadata about the entries, timeseries handles and serves timeseriese which are linked to contet entries.
the first task i assign you is to analyze content swagger, analyzing all endpoints and parameters. you then are tasked in the creation of an LLM readible document explaining each endpoint parameters, utility and response format, how
 to use rawfilters, what are select clause doing. the deliverable is a document we can use later to build api calls when developing the discovery web app.

i will provide you the swaggers diveided by entity in @OdhDiscovery/context/content_swaggers/*.json use them to perform calls against the correct server.

To better undertand how to use the apis i provide you with some documentation @OdhDiscovery/context/content_rawsort_rawfilter.md @OdhDiscovery/context/content_field_selection.md 
@OdhDiscovery/context/content_geosorting_locationfilter.md . You have to read and understand these files before analyzing the swaggers and i want the deliverable file to contains these notions (rewritten to be more LLM friendly) as 
well.

- Only analyze read operationa
- Use local swagger for Sensors
- Use the other Swagger for all other endpoints
- Read/analyze/understand the existing documentation (md files)
- Deliver an LLM ready file containing instructions on how to use rawfilters,sort,geofilter,selection, ... and the endpoint analysis results (parameters, endpoint, result strcture)
- Deliverable is called "CONTEXT_CONTENT.md" in in @OdhDiscovery/

DO NOT RUN A SUPERFICIAL ANALYSIS, THIS FILE WILL BE USED AS FUNDATION TO BUILD THE WE APPLICATION 

--------
we are about to create a discovery web application to let users, developers and maintainers to browse the data contained in my data sharing platform. before diving into that we need to create some meaningful context.
we have 2 different services: content and timeseries. content handles and serves static / medatadata about the entries, timeseries handles and serves timeseriese which are linked to content entries.
the first task i assign you is to analyze content swagger, analyzing all endpoints and parameters. you then are tasked in the creation of an LLM readible document explaining each endpoint parameters, utility and response format, how
 to use rawfilters, what are select clause doing. the deliverable is a document we can use later to build api calls when developing the discovery web app.

i will provide you the swaggers diveided by entity in @OdhDiscovery/context/timeseries_swagger/*.json use them to perform calls against the correct server.

To better undertand how to use the apis i provide you with some documentation @OdhDiscovery/context/timeseries_value_filter.md . You have to read and understand these files before analyzing the swaggers and i want the deliverable file to contains these notions (rewritten to be more LLM friendly) as 
well.

- Only analyze read operationa
- Use local swagger for Sensors
- Use the other Swagger for all other endpoints
- Read/analyze/understand the existing documentation (md files)
- Deliver an LLM ready file containing instructions on how to use rawfilters,sort,geofilter,selection, ... and the endpoint analysis results (parameters, endpoint, result strcture)
- Deliverable is called "CONTEXT_TIMESERIES.md" in in @OdhDiscovery/

DO NOT RUN A SUPERFICIAL ANALYSIS, THIS FILE WILL BE USED AS FUNDATION TO BUILD THE WE APPLICATION 

--------
we are about to create a discovery web application to let users, developers and maintainers to browse the data contained in my data sharing platform. before diving into that we need to create some meaningful context.
we have 2 different services: content and timeseries. content handles and serves static / medatadata about the entries, timeseries handles and serves timeseriese which are linked to contet entries.
the first task i assign you is to read 2 swaggers, keep inly read endpoints, and output one swagger per tag/entity (swagegr section) to make them more readible and chunked.
keep the server url in each output swagger since they refer to different servers. 
@OdhDiscovery/context/content_swagger_local.json must be used ONLY for "sensor" endpoints.
@OdhDiscovery/context/content_swagger.json must be used for all other endpoints.

output swaggers in @OdhDiscovery/context/swaggers/

--------
we are about to create a discovery web application to let users, developers and maintainers to browse the data contained in my data sharing platform. before diving into that we need to create some meaningful context.
we have 2 different services: content and timeseries. content handles and serves static / medatadata about the entries, timeseries handles and serves timeseriese which are linked to content entries.
You are tasked with creating the web app following the below requirements:

- Vue3
- Pinia
- Composition api

api references:
@OdhDiscovery/CONTEXT_CONTENT.md
@OdhDiscovery/CONTEXT_TIMESERIES.md

requisites:
As a person approaching the open data hub trying to undestand what it does and if it fits my needs i want:

- Be able to browser the concept of dataset
What does the dataset describes
How big is the dataset
How complete is the dataset
How the data structure looks like
How complete are fields in the dataset (pct)
How is the format of each field (examples)
How to retrive the dataset from api call
Are there timeseries attached to the dataset?
What timeseries are attached to the dataset?
What is the probability of each timeseries to be attached to an entry?

- Inspect the dataset(s)
Get a tableview of the entries of the dataset calling the api
Button to switch to raw view (formatted collapsible searchable json response)
Still visualize aggregated information of the dataset:
    How the data structure looks like
    How complete are fields in the dataset (pct)
    How is the format of each field (examples)
    Are there timeseries attached to the dataset?
    What timeseries are attached to the dataset?
    What is the probability of each timeseries to be attached to an entry?
Filter data using 2 different approaches:
    The presence (not null) of each property of the dataset (including mapping and dynamic and timeseries)
    Normal filter about property values
Every time a filter is applied the grid/raw json updates and the composed api request is still shown (curl) on top for reprudicibility.
Every time a filter is applied the aggregated information of the dataset are updated using the filtered results.
Button to open "Bulk inspect for timeseries(s)" page with all filtered entries

- Be able to browse the concept of timeseries
what datatypes are avaliable
What do them represent
How many sensors have this timeseries
what is the value type (number, string, geometry, ...)
what are the distinct entity types (datasets) implementing the timeseries
what percentage of entries of each entity type (datset) implement the timeseries

- Inspect the timeseries(s)
Get a tableview of entries implementing the timeseries
get a tableview of entity types (datasets) implementing the timeseries
filter over them

- Bulk inspect for timeseries(s)
Once selected some entries (might them be filtered by "Inspect the dataset(s)" page or "Inspect the timeseries(s)") i want to see al selectable (multiselect) timeseries types.
Selecting the timeseries types the timeseries gets loaded for all entries.
I can unselect some entries.
data is displayed depending on the type but simultaneously for all entries.
display table tab:
    all measurements are displayed as table, all together regardless the type
display raw tab:
    response is displayed as formatted collapsible searchable json response
display formatted tab:
    numeric timeseries 
        are plotted in a chart.
        can switch to table
    string timeseries
        table
    boolean timeseries
        table
    geoshape/geoposition:
        map witht the shole timeseries
        can switch to "instant" view witha  slider where only the measurement at that time is shown on the map
    json timeseries
        are plotted as rable containing the jsons
        can switch to detailed view
            in detailed view the list of distinct keys is shown and by selecting them the section expands replicating the root visualizion (reference to "display formatted tab:" section)
            detailed view is basically a "display formatted tab" inside the json timeseries section (display formatted tab in display formatted tab).



------------

read @WEBAPP_DOCUMENTATION.md . now that you know how the application works i want you to help planning the next steps.
  i woud like to create a chatbot integrated in the webapp.
  the chatbot shoult be able to anwser user question about the timeseries and datasets by performin live ondemand analysis using the same endpoints and logic used by the webapp, basically making the work of
  analyze the webapp result in behalf of the user.
  additionally i woult like the bot to navigate, when needed or appriopriate, the web app to the right page with the right url configuration, to justify and show the user the results (or from what he got) the
  results.
  i am not experienced in chatbot and agents built with langchain or langgraph. i expect i should have a bit of vector dabase to store contextual or static informations, but other than that i don't know what kind
  of reasoning flow, tools to create and how to properly integrate the bot backand with the frontend so that it can "control" the web app.
  i'm also very concerned about the length of the api responses, i think we should foresee some tools to filter, aggreagate and handle very long api response to avoid contxt exhaustion or high costs; are there best-practices, packages or approacesh to adopt?

  can you make a detailed and appriopriate plan on the design, architecture, stack and implementataion of this bot?


  -------------
  content api has an endpoint containing information about datasets. it also contain the path, query params and other data about how to build the url to get the entries of the datasets. basically is a blueprint for datasets.
  the url is content_host/v1?pagenumber=1&removenullvalues=true where the host is https://tourism.opendatahub.com.
  you have to anlyze all entries of the medata to undestand the structure and then you have to build a query builder in the webapp so that we can populate Dataset page with real datasets. Metadata dataset must be included as well and you must hardcode Sensor since it is not registered. modify @OdhDiscovery/webapp/src/api/contentApi.js where datasets were hardcoded.
  the behavuoir must be that the DatasetPage calls metadataapi to get all datasets plus sensors plus metadata. @OdhDiscovery/webapp/src/views/DatasetInspector.vue must look at url path to get the metadata searching for Shortnameand build the url to get entries using that as key. every time the page loads you have to get the metadata from metadataapi to build the api url.
  the result looks like:

  {
  "TotalResults": 173,
  "TotalPages": 18,
  "CurrentPage": 1,
  "PreviousPage": null,
  "NextPage": "https://tourism.opendatahub.com/v1/MetaData?pagenumber=2&removenullvalues=true",
  "Seed": null,
  "Items": [
    {
      "Id": "00109544-2a58-4051-b619-b350e0035d20",
      "Self": "https://tourism.opendatahub.com/v1/MetaData/00109544-2a58-4051-b619-b350e0035d20",
      "Type": "odhactivitypoi",
      "_Meta": {
        "Id": "00109544-2a58-4051-b619-b350e0035d20",
        "Type": "odhmetadata",
        "Source": "noi",
        "Reduced": false,
        "LastUpdate": "2024-11-07T16:19:36.1074157+00:00",
        "UpdateInfo": {
          "UpdatedBy": "r.thoeni@noi.bz.it",
          "UpdateSource": "https://databrowser.opendatahub.com/"
        }
      },
      "ApiUrl": "https://tourism.api.opendatahub.com/v1/ODHActivityPoi?tagfilter=museums",
      "ApiType": "content",
      "BaseUrl": "https://tourism.api.opendatahub.com",
      "ApiFilter": [
        "tagfilter=museums"
      ],
      "Dataspace": "tourism",
      "PathParam": [
        "v1",
        "ODHActivityPoi"
      ],
      "Shortname": "Museums",
      "Deprecated": false,
      "LastChange": "2024-11-07T16:19:36.1074157+00:00",
      "SwaggerUrl": "https://tourism.api.opendatahub.com/swagger/index.html#/ODHActivityPoi",
      "FirstImport": "2023-09-18T07:48:09.6544784+00:00",
      "LicenseInfo": {
        "Author": "https://noi.bz.it",
        "License": "CC0",
        "ClosedData": false,
        "LicenseHolder": "https://noi.bz.it"
      },
      "DataProvider": [
        "SIAG",
        "LTS"
      ],
      "ImageGallery": [
        {
          "License": "CC0",
          "ImageUrl": "https://images.opendatahub.com/api/Image/GetImage?imageurl=a308d8ba-b7d0-4cb2-9dc9-143c2af150f8.jpg",
          "ImageSource": "pexels.com"
        }
      ],
      "ApiDescription": {
        "en": "This dataset contains all points of interest that have the tag 'museums' assigned by IDM."
      }
    },
    {
      "Id": "044e4651-2e05-45fd-8bb8-1f795806ffde",
      "Self": "https://tourism.opendatahub.com/v1/MetaData/044e4651-2e05-45fd-8bb8-1f795806ffde",
      "Type": "odhactivitypoi",
      "_Meta": {
        "Id": "044e4651-2e05-45fd-8bb8-1f795806ffde",
        "Type": "odhmetadata",
        "Source": "noi",
        "Reduced": false,
        "LastUpdate": "2024-11-07T16:20:06.1569607+00:00",
        "UpdateInfo": {
          "UpdatedBy": "r.thoeni@noi.bz.it",
          "UpdateSource": "https://databrowser.opendatahub.com/"
        }
      },
      "ApiUrl": "https://tourism.api.opendatahub.com/v1/ODHActivityPoi?tagfilter=traffic and transport",
      "ApiType": "content",
      "BaseUrl": "https://tourism.api.opendatahub.com",
      "ApiFilter": [
        "tagfilter=traffic and transport"
      ],
      "Dataspace": "mobility",
      "PathParam": [
        "v1",
        "ODHActivityPoi"
      ],
      "Shortname": "Traffic and Transport",
      "Deprecated": false,
      "LastChange": "2024-11-07T16:20:06.1569607+00:00",
      "SwaggerUrl": "https://tourism.api.opendatahub.com/swagger/index.html#/ODHActivityPoi",
      "FirstImport": "2023-09-18T07:53:23.9016077+00:00",
      "LicenseInfo": {
        "Author": "https://noi.bz.it",
        "License": "CC0",
        "ClosedData": false,
        "LicenseHolder": "https://noi.bz.it"
      },
      "DataProvider": [
        "STA",
        "LTS"
      ],
      "ImageGallery": [
        {
          "License": "CC0",
          "ImageUrl": "https://images.opendatahub.com/api/Image/GetImage?imageurl=98b1743e-0117-4ab6-8a7f-92128980c703.jpg",
          "ImageSource": "pexels.com"
        }
      ],
      "ApiDescription": {
        "en": " This dataset profiles transportation services such as taxis, chauffeured rental cars, and buses, offering detailed insights including service types, locations, GPS coordinates, and contact information, along with language and update details."
      }
    },


---------------

about @OdhDiscovery/chatbot/backend/tools/navigation.py the idea behind it is to allow the agent to send to the client an extra response field where he suggest to navigate to the url.
the navication command should not always be sent to the client, only when the answer or the data used to answer suit one of the frontend pages and it would be nice to have the frontend enhance the response.
for example when answering that there are some datasets, navigating to the datasetbrowser path with proper filtr could help.
same with types or sensors attached to the type.

i realized a summary of the available views with the parameters. i now want you to check wether the tool works as intented, if it is documented as intended and is integrated in the agent though process as well.

## URL Parameters Reference

This section provides a comprehensive reference of all URL query parameters supported by each route. All parameters are optional unless otherwise specified.

### Route: `/datasets` (DatasetBrowser)

Browse and filter available dataset types.

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `dataspace` | string | `null` | Filter datasets by dataspace (e.g., "tourism", "mobility") |
| `apiType` | string | `null` | Filter datasets by API type (e.g., "content", "timeseries") |
| `datasets` | array | `[]` | Comma-separated list of dataset names to filter (multiselect filter) |
| `page` | number | `1` | Current page number for pagination (20 items per page) |

**Example URLs:**
```
/datasets
/datasets?search=accommodation
/datasets?dataspace=tourism&page=2
/datasets?datasets=Accommodation,Activity&apiType=content
```

---

### Route: `/datasets/:datasetName` (DatasetInspector)

Inspect and analyze a specific dataset with its entries.

**Route Parameters:**
- `:datasetName` - Name of the dataset (e.g., "Accommodation", "Activity", "Poi")

**Query Parameters:**

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `page` | number | `1` | Current page number for entry pagination |
| `pagesize` | number | `50` | Number of entries to display per page (max depends on API) |
| `view` | string | `'table'` | Active view tab: `'table'`, `'raw'`, `'analysis'`, `'distinct'`, `'timeseries'` |
| `rawsort` | string | `null` | ODH raw sort expression (e.g., `'Id desc'`, `'Name asc'`) |
| `fields` | array | `[]` | Comma-separated list of field names to display in table view |
| `language` | string | `null` | Language code for filtering content (e.g., `'en'`, `'de'`, `'it'`) |
| `searchfilter` | string | `null` | Full-text search query across all fields |
| `selectedIds` | array | `[]` | Comma-separated list of selected entry IDs |
| `presenceFilters` | array | `[]` | Comma-separated list of field names to filter for non-null values |
| `distinctProperties` | array | `[]` | Comma-separated list of field paths to analyze for distinct values |

**Special Notes:**
- `rawfilter` parameter is auto-generated from `presenceFilters` and not directly modifiable via URL
- `presenceFilters` generates queries like `field1 ne null and field2 ne null`
- `distinctProperties` triggers distinct value analysis when non-empty and `view=distinct`

**Example URLs:**
```
/datasets/Accommodation
/datasets/Accommodation?page=2&pagesize=100
/datasets/Activity?view=analysis
/datasets/Poi?searchfilter=bolzano&language=en
/datasets/Event?presenceFilters=EventDate,LocationInfo.Name
/datasets/Accommodation?view=distinct&distinctProperties=Type,Features
/datasets/GastronomicData?rawsort=Name asc&fields=Id,Name,ContactInfos
```

---

### Route: `/timeseries` (TimeseriesBrowser)

Browse and filter available timeseries measurement types.

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `dataType` | string | `null` | Filter by data type: `'numeric'`, `'string'`, `'boolean'`, `'json'`, `'geoposition'`, `'geoshape'` |
| `timeseries` | array | `[]` | Comma-separated list of timeseries type names to filter (multiselect filter) |
| `page` | number | `1` | Current page number for pagination (20 items per page) |

**Example URLs:**
```
/timeseries
/timeseries?dataType=numeric
/timeseries?timeseries=temperature,humidity&page=1
/timeseries?page=2
```

---

### Route: `/timeseries/:typeName` (TimeseriesInspector)

Inspect sensors and measurements for specific timeseries types.

**Route Parameters:**
- `:typeName` - Name of the timeseries type (legacy parameter, now supports multiple types via query params)

**Query Parameters:**

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `types` | array | `[]` | Comma-separated list of timeseries type names to inspect (e.g., `'temperature,humidity'`) |
| `view` | string | `'table'` | Display mode: `'table'` (sensor table), `'raw'` (JSON viewer) |
| `filter` | JSON | `null` | Advanced filter object (JSON-encoded, reserved for future filtering features) |
| `selectedSensors` | array | `[]` | Comma-separated list of selected sensor names for bulk operations |

**Special Notes:**
- If `types` array is empty, the route parameter `:typeName` is used as the single type
- Multiple types can be selected and viewed simultaneously
- `selectedSensors` is used when navigating to bulk measurements view

**Example URLs:**
```
/timeseries/temperature
/timeseries/temperature?types=temperature,humidity
/timeseries/air_quality?view=raw
/timeseries/temperature?selectedSensors=sensor1,sensor2,sensor3
/timeseries/weather?types=temperature,humidity,pressure&view=table
```

---

### Route: `/bulk-measurements` (BulkMeasurementsInspector)

Load and visualize measurements for multiple sensors and types.

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `sensors` | array | `[]` | **Required.** Comma-separated list of sensor names to query for measurements |
| `types` | array | `[]` | Comma-separated list of measurement type names currently selected for loading |
| `disabledSensors` | array | `[]` | Comma-separated list of sensor names to exclude from API queries (shown with strikethrough in UI) |
| `view` | string | `'table'` | Display mode: `'table'`, `'raw'`, `'pretty'` |

**View Modes:**
- `'table'` - Simple tabular view of measurements
- `'raw'` - Raw JSON viewer with full measurement data
- `'pretty'` - Auto-detected visualizations based on data type:
  - **Numeric** → Chart.js time-series line chart
  - **Geographic** → Leaflet map with WKT/GeoJSON support
  - **String/Boolean** → Enhanced table view
  - **JSON** → Expandable tree viewer

**Special Notes:**
- `sensors` parameter is required - without it, the page shows an empty state
- Enabled sensors = `sensors` minus `disabledSensors`
- Only enabled sensors are sent to API when loading measurements
- The `types` array determines which checkboxes are pre-selected but doesn't trigger loading until user clicks "Load Latest" or "Load Historical"
- Disabling a sensor updates `disabledSensors` in URL and reloads available types

**Example URLs:**
```
/bulk-measurements?sensors=sensor1,sensor2,sensor3
/bulk-measurements?sensors=hotel-1,hotel-2&types=temperature,humidity
/bulk-measurements?sensors=s1,s2,s3,s4&disabledSensors=s2,s4&view=pretty
/bulk-measurements?sensors=air-quality-1,air-quality-2&types=pm10,pm25&view=table
```

**Typical Workflow:**
1. User navigates from Dataset Inspector or Timeseries Inspector with `sensors` param populated
2. Page loads available types for enabled sensors via API call
3. User selects desired types (updates `types` in URL)
4. User clicks "Load Latest" or "Load Historical Range"
5. Measurements are fetched and displayed in selected view mode

---------------
does the chatbot handle chatmemory? i want the user to be able to continue the conversation.
lets use an inmemroy storage for now.
i want the bot to answer in streaming mode to give the chatbot feeling

----------------
now is the time for the integration with the frontend.
create a chatbot component in the webbap @OdhDiscovery/webapp.
the webapp is in vue3 using composition api.
the chat should of course connect to the ws and store the conversation id to continue it. should we store the conversation id in the local storage?
the chat has a toggle to enable / disable the auto navigation. if the navigation is enabled, when the bot sends a navigtion command with the response we webbapp navigtes there (with router push). in any case the chat appends an href the user can click anyway.
having it in streaming mode woule be nice.
the chat must retrive all old messages, if a session is present and populate the chat with the message without "following" the navigation even if the toggle is activated.
the chat must be a root level component, have a floating button activator like normal support chats, be resizable and must include a "new chat" button to reset the session and the chat.